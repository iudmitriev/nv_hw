name: FastSpeech2
n_gpu: 1
preprocessing:
  sr: 22050
  subsample_size: 16384
  spectrogram:
    _target_: src.spectrogram.MelSpectrogram
    config: 
      _target_: src.spectrogram.MelSpectrogramConfig
arch:
  _target_: src.model.HiFiGANModel
  input_channels: 80
  hidden_dim: 512
  upsample_conv_kernel_sizes: [16, 16, 4, 4]
  upsample_conv_strides: [8, 8, 2, 2]
  block_kernel_sizes: [3, 7, 11]
  block_dilation_sizes: [[[1, 1], [3, 1], [5, 1]], [[1, 1], [3, 1], [5, 1]], [[1, 1], [3, 1], [5, 1]]]
  periods: [2, 3, 5, 7, 11]
data:
  train:
    batch_size: 10
    num_workers: 5
    datasets:
      train:
        _target_: src.datasets.LJspeechDataset
        part: "train"
        max_audio_length: 20.0
  val:
    batch_size: 10
    num_workers: 5
    datasets:
      test:
        _target_: src.datasets.LJspeechDataset
        part: "test"
        max_audio_length: 20.0
        limit: 1024
optimizer:
  generator_optimizer:
    _target_: torch.optim.AdamW
    lr: 2e-4
    weight_decay: 0.01
    betas: [0.8, 0.99]
  discriminator_optimizer:
    _target_: torch.optim.AdamW
    lr: 2e-4
    weight_decay: 0.01
    betas: [0.8, 0.99]
loss:
  generator_loss:
    _target_: src.loss.GeneratorLoss
  discriminator_loss:
    _target_: src.loss.DiscriminatorLoss
lr_scheduler:
  generator_lr_scheduler:
    _target_: torch.optim.lr_scheduler.ExponentialLR
    gamma: 0.999
  discriminator_lr_scheduler:
    _target_: torch.optim.lr_scheduler.ExponentialLR
    gamma: 0.999
trainer:
  epochs: 50
  test_dir: "test_wavs/"
  save_dir: "saved/"
  save_period: 5
  verbosity: 2
  monitor: "min generator_loss"
  early_stop: 200
  visualize: "wandb"
  wandb_project: "nv_project"
